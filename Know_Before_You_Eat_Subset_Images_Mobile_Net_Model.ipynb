{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, GlobalAveragePooling2D, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.applications import VGG16, Xception, InceptionV3, MobileNet, ResNet50\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4076 images belonging to 101 classes.\n",
      "Found 1078 images belonging to 101 classes.\n",
      "Found 1299 images belonging to 101 classes.\n",
      "128.0\n",
      "34.0\n",
      "1299.0\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "shape = (224, 224)\n",
    "\n",
    "# data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    horizontal_flip=True, \n",
    "    width_shift_range=0.1, \n",
    "    height_shift_range=0.2, \n",
    "    rotation_range=10, \n",
    "    zoom_range=0.05, \n",
    "    brightness_range=[0.4, 0.8],\n",
    "    fill_mode=\"reflect\"\n",
    "    ) \n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    directory=\"subset_images/train\",\n",
    "    target_size=shape,\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\",\n",
    "    seed=2019)\n",
    "\n",
    "valid_generator = datagen.flow_from_directory(\n",
    "    directory=\"subset_images/valid\",\n",
    "    target_size=shape,\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\",\n",
    "    seed=2019)\n",
    "\n",
    "test_generator = datagen.flow_from_directory(\n",
    "    directory=\"subset_images/test\",\n",
    "    target_size=shape,\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=False,\n",
    "    batch_size=1,\n",
    "    class_mode=\"categorical\")\n",
    "\n",
    "num_classes = len(train_generator.class_indices)\n",
    "\n",
    "# create step size\n",
    "STEP_SIZE_TRAIN=np.ceil(train_generator.n/train_generator.batch_size)\n",
    "STEP_SIZE_VALID=np.ceil(valid_generator.n/valid_generator.batch_size)\n",
    "STEP_SIZE_TEST=np.ceil(test_generator.n/test_generator.batch_size)\n",
    "\n",
    "print(STEP_SIZE_TRAIN)\n",
    "print(STEP_SIZE_VALID)\n",
    "print(STEP_SIZE_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(shape[0], shape[1], 3), padding='same', use_bias=False, kernel_regularizer=l2(1e-4)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(shape[0], shape[1], 3), padding='same', use_bias=False, kernel_regularizer=l2(1e-4)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(2,2))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same', use_bias=False, kernel_regularizer=l2(1e-4)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, (3, 3), padding='same', use_bias=False, kernel_regularizer=l2(1e-4)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(2,2))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding='same', use_bias=False, kernel_regularizer=l2(1e-4)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(num_classes, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(lr=0.0001, decay=1e-6),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks\n",
    "earlyStopping = EarlyStopping(monitor=\"val_loss\", patience=10, verbose=0, mode=\"min\")\n",
    "checkpoint = ModelCheckpoint(os.path.join(\"models\", \"model-{epoch:03d}-{acc:03f}-{val_acc:03f}.h5\"), verbose=1, \n",
    "                             monitor=\"val_loss\", save_best_only=True, mode=\"auto\")\n",
    "reduce_lr_loss = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=7, verbose=1, min_delta=1e-4, mode=\"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import missinglink\n",
    "missinglink_callback = missinglink.KerasCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit base model\n",
    "model.fit(train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    callbacks=[missinglink_callback,earlyStopping, checkpoint, reduce_lr_loss],\n",
    "                    epochs=10, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning => MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load base MobileNet\n",
    "base_mn = MobileNet(weights='imagenet', include_top=False, input_shape=(shape[0], shape[1], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_block = base_mn.output\n",
    "\n",
    "top_block = GlobalAveragePooling2D()(top_block) # pool over height/width to reduce number of parameters\n",
    "top_block = Dense(256, activation='relu')(top_block) # add a Dense layer\n",
    "predictions = Dense(num_classes, activation='softmax')(top_block) # add another Dense layer\n",
    "mn_transfer = Model(inputs=base_mn.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unfreeze last few layers\n",
    "for i, layer in enumerate(reversed(mn_transfer.layers)):\n",
    "    layer.trainable = True\n",
    "    if i > 15:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "mn_transfer.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=RMSprop(lr=0.0002),\n",
    "              metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 128.0 steps, validate for 34.0 steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dineshp/.pyenv/versions/3.7.6/lib/python3.7/site-packages/missinglink_kernel/callback/dispatchers/json_encoder.py:24: UserWarning: skipped MissingLinkJsonEncoder because of TypeError Object of type ResourceVariable is not JSON serializable\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "127/128 [============================>.] - ETA: 8s - loss: 3.3241 - acc: 0.2727 \n",
      "Epoch 00001: val_loss improved from inf to 2.76175, saving model to models/keras_models/model-mobilenet-RMSprop0.0002-001-0.274289-0.346939.h5\n",
      "128/128 [==============================] - 1208s 9s/step - loss: 3.3159 - acc: 0.2743 - val_loss: 2.7617 - val_acc: 0.3469\n",
      "Epoch 2/50\n",
      "127/128 [============================>.] - ETA: 9s - loss: 1.4061 - acc: 0.6716 \n",
      "Epoch 00002: val_loss improved from 2.76175 to 1.86082, saving model to models/keras_models/model-mobilenet-RMSprop0.0002-002-0.673454-0.520408.h5\n",
      "128/128 [==============================] - 1232s 10s/step - loss: 1.3996 - acc: 0.6735 - val_loss: 1.8608 - val_acc: 0.5204\n",
      "Epoch 3/50\n",
      "127/128 [============================>.] - ETA: 8s - loss: 0.7063 - acc: 0.8321 \n",
      "Epoch 00003: val_loss improved from 1.86082 to 1.39983, saving model to models/keras_models/model-mobilenet-RMSprop0.0002-003-0.831207-0.635436.h5\n",
      "128/128 [==============================] - 1177s 9s/step - loss: 0.7087 - acc: 0.8312 - val_loss: 1.3998 - val_acc: 0.6354\n",
      "Epoch 4/50\n",
      "127/128 [============================>.] - ETA: 8s - loss: 0.3614 - acc: 0.9258 \n",
      "Epoch 00004: val_loss improved from 1.39983 to 1.30251, saving model to models/keras_models/model-mobilenet-RMSprop0.0002-004-0.925662-0.664193.h5\n",
      "128/128 [==============================] - 1108s 9s/step - loss: 0.3616 - acc: 0.9257 - val_loss: 1.3025 - val_acc: 0.6642\n",
      "Epoch 5/50\n",
      "127/128 [============================>.] - ETA: 8s - loss: 0.1961 - acc: 0.9587 \n",
      "Epoch 00005: val_loss did not improve from 1.30251\n",
      "128/128 [==============================] - 1166s 9s/step - loss: 0.1963 - acc: 0.9585 - val_loss: 1.3099 - val_acc: 0.6512\n",
      "Epoch 6/50\n",
      "127/128 [============================>.] - ETA: 10s - loss: 0.1102 - acc: 0.9839\n",
      "Epoch 00006: val_loss did not improve from 1.30251\n",
      "128/128 [==============================] - 1468s 11s/step - loss: 0.1106 - acc: 0.9838 - val_loss: 1.4025 - val_acc: 0.6373\n",
      "Epoch 7/50\n",
      "127/128 [============================>.] - ETA: 9s - loss: 0.0720 - acc: 0.9899 \n",
      "Epoch 00007: val_loss improved from 1.30251 to 1.27889, saving model to models/keras_models/model-mobilenet-RMSprop0.0002-007-0.989450-0.679963.h5\n",
      "128/128 [==============================] - 1321s 10s/step - loss: 0.0729 - acc: 0.9895 - val_loss: 1.2789 - val_acc: 0.6800\n",
      "Epoch 8/50\n",
      "127/128 [============================>.] - ETA: 9s - loss: 0.0568 - acc: 0.9891 \n",
      "Epoch 00008: val_loss did not improve from 1.27889\n",
      "128/128 [==============================] - 1297s 10s/step - loss: 0.0569 - acc: 0.9890 - val_loss: 1.3717 - val_acc: 0.6772\n",
      "Epoch 9/50\n",
      "127/128 [============================>.] - ETA: 8s - loss: 0.0485 - acc: 0.9871 \n",
      "Epoch 00009: val_loss did not improve from 1.27889\n",
      "128/128 [==============================] - 1232s 10s/step - loss: 0.0486 - acc: 0.9870 - val_loss: 1.3426 - val_acc: 0.6911\n",
      "Epoch 10/50\n",
      "127/128 [============================>.] - ETA: 8s - loss: 0.0294 - acc: 0.9960 \n",
      "Epoch 00010: val_loss did not improve from 1.27889\n",
      "128/128 [==============================] - 1206s 9s/step - loss: 0.0293 - acc: 0.9961 - val_loss: 1.3023 - val_acc: 0.6753\n",
      "Epoch 11/50\n",
      "127/128 [============================>.] - ETA: 8s - loss: 0.0311 - acc: 0.9926 \n",
      "Epoch 00011: val_loss did not improve from 1.27889\n",
      "128/128 [==============================] - 1199s 9s/step - loss: 0.0312 - acc: 0.9926 - val_loss: 1.3603 - val_acc: 0.6846\n",
      "Epoch 12/50\n",
      "127/128 [============================>.] - ETA: 8s - loss: 0.0194 - acc: 0.9973 \n",
      "Epoch 00012: val_loss did not improve from 1.27889\n",
      "128/128 [==============================] - 1215s 9s/step - loss: 0.0194 - acc: 0.9973 - val_loss: 1.4827 - val_acc: 0.6401\n",
      "Epoch 13/50\n",
      "127/128 [============================>.] - ETA: 9s - loss: 0.0238 - acc: 0.9946 \n",
      "Epoch 00013: val_loss did not improve from 1.27889\n",
      "128/128 [==============================] - 1356s 11s/step - loss: 0.0241 - acc: 0.9941 - val_loss: 1.4835 - val_acc: 0.6707\n",
      "Epoch 14/50\n",
      "127/128 [============================>.] - ETA: 8s - loss: 0.0160 - acc: 0.9973 \n",
      "Epoch 00014: val_loss did not improve from 1.27889\n",
      "128/128 [==============================] - 1231s 10s/step - loss: 0.0163 - acc: 0.9971 - val_loss: 1.4824 - val_acc: 0.6716\n",
      "Epoch 15/50\n",
      "127/128 [============================>.] - ETA: 9s - loss: 0.0239 - acc: 0.9936 \n",
      "Epoch 00015: val_loss did not improve from 1.27889\n",
      "128/128 [==============================] - 1281s 10s/step - loss: 0.0237 - acc: 0.9936 - val_loss: 1.5223 - val_acc: 0.6623\n",
      "Epoch 16/50\n",
      "127/128 [============================>.] - ETA: 9s - loss: 0.0169 - acc: 0.9958 \n",
      "Epoch 00016: val_loss did not improve from 1.27889\n",
      "128/128 [==============================] - 1286s 10s/step - loss: 0.0168 - acc: 0.9958 - val_loss: 1.5549 - val_acc: 0.6753\n",
      "Epoch 17/50\n",
      "127/128 [============================>.] - ETA: 9s - loss: 0.0141 - acc: 0.9963 \n",
      "Epoch 00017: val_loss did not improve from 1.27889\n",
      "128/128 [==============================] - 1240s 10s/step - loss: 0.0140 - acc: 0.9963 - val_loss: 1.4979 - val_acc: 0.6865\n"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "checkpoint3 = ModelCheckpoint(os.path.join(\"models\",\"keras_models\", \"model-mobilenet-RMSprop0.0002-{epoch:03d}-{acc:03f}-{val_acc:03f}.h5\"), \n",
    "                              verbose=1, monitor=\"val_loss\", save_best_only=True, mode=\"auto\")\n",
    "history_mn = mn_transfer.fit(train_generator,\n",
    "                                       steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                                       validation_data=valid_generator,\n",
    "                                       validation_steps=STEP_SIZE_VALID,\n",
    "                                       callbacks=[missinglink_callback,earlyStopping, checkpoint3],\n",
    "                                       epochs=50, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "#model-mobilenet-RMSprop0.0002-001-0.930507-0.647776.h5\n",
    "transfer = load_model(os.path.join(\"models\",\"keras_models\", \"model-mobilenet-RMSprop0.0002-001-0.998528-0.692950.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile\n",
    "transfer.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=SGD(lr=0.0001), \n",
    "              metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 128.0 steps, validate for 34.0 steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dineshp/.pyenv/versions/3.7.6/lib/python3.7/site-packages/missinglink_kernel/callback/dispatchers/json_encoder.py:24: UserWarning: skipped MissingLinkJsonEncoder because of TypeError Object of type ResourceVariable is not JSON serializable\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      "127/128 [============================>.] - ETA: 10s - loss: 0.0036 - acc: 0.9995\n",
      "Epoch 00003: val_loss improved from inf to 1.47888, saving model to models/keras_models/model-mobilenet-RMSprop0.0002to0.0001-003-0.999509-0.720779.h5\n",
      "128/128 [==============================] - 1402s 11s/step - loss: 0.0036 - acc: 0.9995 - val_loss: 1.4789 - val_acc: 0.7208\n",
      "Epoch 4/10\n",
      "127/128 [============================>.] - ETA: 10s - loss: 0.0050 - acc: 0.9988\n",
      "Epoch 00004: val_loss improved from 1.47888 to 1.40935, saving model to models/keras_models/model-mobilenet-RMSprop0.0002to0.0001-004-0.998773-0.719852.h5\n",
      "128/128 [==============================] - 1406s 11s/step - loss: 0.0050 - acc: 0.9988 - val_loss: 1.4094 - val_acc: 0.7199\n",
      "Epoch 5/10\n",
      "127/128 [============================>.] - ETA: 9s - loss: 0.0044 - acc: 0.9993 \n",
      "Epoch 00005: val_loss improved from 1.40935 to 1.40466, saving model to models/keras_models/model-mobilenet-RMSprop0.0002to0.0001-005-0.999264-0.721707.h5\n",
      "128/128 [==============================] - 1289s 10s/step - loss: 0.0044 - acc: 0.9993 - val_loss: 1.4047 - val_acc: 0.7217\n",
      "Epoch 6/10\n",
      "127/128 [============================>.] - ETA: 10s - loss: 0.0047 - acc: 0.9990\n",
      "Epoch 00006: val_loss did not improve from 1.40466\n",
      "128/128 [==============================] - 1430s 11s/step - loss: 0.0047 - acc: 0.9990 - val_loss: 1.4852 - val_acc: 0.7245\n",
      "Epoch 7/10\n",
      " 67/128 [==============>...............] - ETA: 9:06 - loss: 0.0039 - acc: 0.9991"
     ]
    }
   ],
   "source": [
    "# continue fitting\n",
    "checkpoint3 = ModelCheckpoint(os.path.join(\"models\", \"keras_models\", \"model-mobilenet-RMSprop0.0002to0.0001-{epoch:03d}-{acc:03f}-{val_acc:03f}.h5\"), \n",
    "                              verbose=1, monitor=\"val_loss\", save_best_only=True, mode=\"auto\")\n",
    "history_mn = transfer.fit(train_generator,\n",
    "                                       steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                                       validation_data=valid_generator,\n",
    "                                       validation_steps=STEP_SIZE_VALID,\n",
    "                                       callbacks=[missinglink_callback,earlyStopping, checkpoint3],\n",
    "                                       epochs=10, verbose=1, initial_epoch=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate\n",
    "val_loss, val_acc = transfer.evaluate_generator(generator=valid_generator, steps=STEP_SIZE_VALID, verbose=1)\n",
    "print(\"Val Loss: {} \\nVal Accuracy: {}\".format(val_loss, val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict test images\n",
    "test_generator.reset()\n",
    "pred = transfer.predict(test_generator, steps=STEP_SIZE_TEST, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean predictions\n",
    "predictions = pred.argmax(axis=-1)\n",
    "labels = (test_generator.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predicted_labels = [labels[k] for k in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create prediction dataframe\n",
    "filenames = test_generator.filenames\n",
    "correct_labels = [filename[:filename.find(\"/\")] for filename in filenames]\n",
    "results = pd.DataFrame({\"Filename\": filenames, \"Labels\": correct_labels, \"Predicted Label\": predicted_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plots the distribution of the predictions for a given dish\n",
    "\n",
    "\n",
    "def plot_predictions_for_class(data, class_id, figsize=(10,7)):\n",
    "   \n",
    "    subset = data[data[\"Labels\"] == class_id]\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.title(\"Count per Predicted Label\")\n",
    "    plt.xlabel(\"Food Item\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    value_counts = subset[\"Predicted Label\"].value_counts().plot(kind=\"bar\")\n",
    "    return value_counts\n",
    "\n",
    "## Returns top k most accurate predictions\n",
    "    \n",
    "def get_most_accurate(data, k=1):\n",
    "\n",
    "    subset = data[data[\"Labels\"]==data[\"Predicted Label\"]]\n",
    "    results = (subset[\"Labels\"].value_counts()/data[\"Labels\"].value_counts()).sort_values(ascending=False)[:k]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_most_accurate(results,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions_for_class(results, \"apple pie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict 1 image\n",
    "source = \"valid\"\n",
    "random_folder = np.random.choice(os.listdir(os.path.join(\"images\", source)))\n",
    "random_image = np.random.choice(os.listdir(os.path.join(\"images\", source, random_folder)))\n",
    "img = image.load_img(os.path.join( \"images\", source, random_folder, random_image), target_size = (shape[0], shape[1]))\n",
    "plt.imshow(img)\n",
    "img = image.img_to_array(img) / 255\n",
    "img = np.expand_dims(img, axis = 0)\n",
    "\n",
    "print(\"Actual:\", random_image)\n",
    "print(\"Predicted:\", labels[transfer.predict(img).argmax(axis=-1)[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = transfer.evaluate_generator(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.3246215166754547, 0.73364127]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernel_info": {
   "name": "dev"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
